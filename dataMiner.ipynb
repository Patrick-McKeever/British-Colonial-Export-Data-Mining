{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COLONIAL DATA MINING PROJECT\n",
    "\n",
    "### Introduction and PDF Reading\n",
    "\n",
    "I recently enrolled in a political science class which requires me to perform somesort of empirical analysis pertaining to african colonies. After deciding that I wanted to do something pertaining to the growth of export economy in colonial dependencies, I quickly found a dearth of easily-accessible data in convenient formats (e.g. JSON, CSV, etc.). Instead, I found several dozen PDFs originating from the british colonial office, each of which enumerated exported commodities and corresponding monetary values. (For those interested, they can locate these documents by searching on archive.org for documents authored by the \"British colonial office\" from between 1920 and 1938. I chose this time period specifically, because it was the most thoroughly cataloged.)\n",
    "\n",
    "Anyone familiar with PDF parsing can predict some of the issues ahead. As an SO user told me during the initial stages of this project, \"the first rule of pdf parsing is don't\". Unfortunately, the lack of more accessible data formats forced me to pursue PDF parsing. I gradually added to a jupyter notebook file over the course of a couple days until it reached a truly grotesque size (the code approaches around 600 lines total, regrettably making this my largest repo at the moment). It's definitely some of the messier code I've written, but the script functions with a relatively high degree of accuracy. Having recently learned the basics of jupyter's markdown notation, I thought it would be a valuable experience to retroactively annotate my work.\n",
    "\n",
    "To begin, let's extract text from each pdf (all stored in the 'pdf' directory) using poppler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b31409350.pdf\n",
      "b31411514.pdf\n",
      "b31409106.pdf\n",
      "b31409404.pdf\n",
      "b31408990.pdf\n",
      "b31409362.pdf\n",
      "b31410327.pdf\n",
      "b31411472.pdf\n",
      "b31409052.pdf\n",
      "b31409064.pdf\n",
      "b3141283x.pdf\n",
      "b31412865.pdf\n",
      "b31409325.pdf\n",
      "b31409386.pdf\n",
      "b31409398.pdf\n",
      "b31409374.pdf\n",
      "b31411113.pdf\n",
      "b3140943x.pdf\n",
      "b31411071.pdf\n",
      "b31410315.pdf\n",
      "b31411101.pdf\n",
      "b31409003.pdf\n",
      "b31411484.pdf\n",
      "b31409349.pdf\n",
      "b31409076.pdf\n",
      "b31409015.pdf\n",
      "b31409416.pdf\n",
      "b31410273.pdf\n",
      "b31411083.pdf\n",
      "b31411095.pdf\n",
      "b31408989.pdf\n",
      "b31409337.pdf\n",
      "b31409027.pdf\n",
      "b31409301.pdf\n",
      "b31409040.pdf\n",
      "b31410297.pdf\n",
      "b31409428.pdf\n",
      "b31411058.pdf\n",
      "b31409313.pdf\n",
      "b3140909x.pdf\n",
      "b31409088.pdf\n",
      "b31410261.pdf\n",
      "b31411502.pdf\n",
      "b31409118.pdf\n",
      "b31411496.pdf\n",
      "b31409039.pdf\n",
      "b31409295.pdf\n",
      "b3141106x.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import PyPDF2 as pdf\n",
    "from multiprocessing import Pool\n",
    "from poppler import load_from_file, PageRenderer\n",
    "\n",
    "#Take a file from 'pdfs' dir, return arr of its pages' texts.\n",
    "def getText(file):\n",
    "    print(file)\n",
    "    doc = load_from_file('pdfs/' + file)\n",
    "    pages = []\n",
    "    pageNum = 0\n",
    "    \n",
    "    while (pg := doc.create_page(pageNum)):\n",
    "        try:\n",
    "            pages.append(pg.text())\n",
    "            pageNum += 1\n",
    "        #invalid page index.\n",
    "        except AttributeError:\n",
    "            break\n",
    "\n",
    "    return pages\n",
    "\n",
    "pdfs = [file.name for file in os.scandir('pdfs')]\n",
    "texts = { pdf : getText(pdf) for pdf in pdfs }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Export Tables from PDF text\n",
    "\n",
    "Each pdf contains a single table of exports. There are several formats, but we'll offer a brief example to show what's ahead of us:\n",
    "\n",
    "```\n",
    "                                                       1933.                       19 34.\n",
    "              Article.\n",
    "                                              Quantity.        Value.   Quantity.           Value.\n",
    "                                               Tons              £        Tons                £\n",
    "CoCOQ/       •••       •••   •••   •••         5,435           88,013    4,877              69,614\n",
    "Coffee, raw ...                                    3              135        1                  29\n",
    "Cotton, raw ...                                   36              363       77                 906\n",
    "Grain—maize                                        2               23          1                 3\n",
    "Kola-nuts                                         20              488       15                 180\n",
    "Palm kernels                                      88              517      137                 567\n",
    "Other articles                                   —              6,575      —                 6,844\n",
    "                   Total     .                   —         £96,114         —           £78,143\n",
    "                   \n",
    "```\n",
    "\n",
    "This foreshadows several deficiencies of the pdf parser that we'll have to deal with. Notably, it has trouble reading pdfs, inserts arbitrary spaces, has a hard type retaining formatting, and confuses similar characters (i.e. '...' -> '•••'). These are, for the most part, surmountable, so we'll put a pin in that for now.\n",
    "\n",
    "Right now, the task at hand is to distinguish tables that list exports from the surrounding text and, more importantly,from other tables. The most obvious criterion would be to select tables which are in close proximity of the word 'export'. They should also have a list of years at the top separated by large spaces, though we need to make sure that our years regex is relatively general to account for parser errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINING REGEXES.\n",
    "chars = '.+'\n",
    "\n",
    "exportText = '(export.{0,200})'\n",
    "yearRgx = '((19[0-9b ]{2}).{,2}[\\s]+)'\n",
    "\n",
    "#There will be a second rgx to account for cases that this does not cover.\n",
    "expTabRgx1 = '(' + exportText + yearRgx + '{2,}(' + chars + '))'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our above regex captures the entire page after signs that the page will contain an export table (namely, the word 'export', followed by a sequence of at most 200 characters, followed by a list of space-demarcated years in the table's header). From that, we can make sure that we capture all of the table on that page. At this point, we'll need to search through the page's content to disaggregate the table from everything else.\n",
    "\n",
    "We can develop a rough heuristic for whether a line belongs to a table by observing the presence of large spaces. Of course, many lines that are contained within a table don't match this; perhaps the line is a label for a commodity which has been bifurcated across multiple lines (e.g. ex. 1), or perhaps we're dealing with a quirk of the pdf parser (ex. 2).\n",
    "\n",
    "\n",
    "#### EX. 1:\n",
    "\n",
    "```\n",
    "Skins, sheep and\n",
    "  goat ...             No.         _            _\n",
    "                                                       952,494 1,559,272 1,566,115\n",
    "```\n",
    "\n",
    "#### EX 2:\n",
    "\n",
    "```\n",
    "Tobacco 2,303 257,998 3,145 352,348 3,088 345,872 4,081 457,122 6,905 780,964\n",
    "```\n",
    "\n",
    "As a result, we're not just looking for table lines; we're looking for an area containing a high concentration of table lines.  To define a regex for tables, we'l look for at a set of table lines separated by at most 1 broken or non-table lines. (A broken line is a line which uses the term '¬' to break up a word.) These are just heuristics, we'll still have plenty of filtering to do later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#At least 2 repetitions of ' '.\n",
    "largeSpaces = ' {2,}'\n",
    "\n",
    "\n",
    "#Characters separated by large spaces, as is the case in tables.\n",
    "tableLine = '(\\n?(' + chars + largeSpaces + chars + ')\\n?)'\n",
    "\n",
    "#Just a line of characters.\n",
    "nonTableLine = '(\\n?(' + chars + ')\\n?)'\n",
    "#Pdf reader denotes dash to s\n",
    "brokenLine = '(.+¬\\n.)'\n",
    "brokOrNonTab = brokenLine + '?' + nonTableLine + '{0,2}'\n",
    "\n",
    "#A table is defined as a set of table lines separated by\n",
    "#at most 1 non-table lines.\n",
    "tableRgx = '((' + tableLine + '+' + brokOrNonTab + ')+)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also mentioned that our initial export table regex wouldn't match all cases. We'll need a second to account for a handful of exceptions.\n",
    "\n",
    "We'll make a function to take a page worth of text as input, search for each of the regexes, and return the results matching the parameters we've outlined as indicative of an export table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "expTabRgx2 = '(' + exportText + tableRgx + ')'\n",
    "\n",
    "#It is necessary to parse pages with multiple regexes, since the first may fail.\n",
    "def getExportPage(pageText, expTabRgx1, expTabRgx2):\n",
    "    results1 = [res[0] for res in\n",
    "                re.findall(expTabRgx1, pgText,\n",
    "                re.IGNORECASE | re.DOTALL) ]\n",
    "    results2 = [res[0] for res in\n",
    "                re.findall(expTabRgx2, pgText,\n",
    "                re.IGNORECASE | re.DOTALL) ]\n",
    "    \n",
    "    results = results1 if results1 else results2\n",
    "    \n",
    "    #If a table is sideways, we can't use it. The parser produces gibberish.\n",
    "    #For some reason, the '®' pops up a lot in sideways tables, so we'll filter it out.\n",
    "    isSideways = any(['®' in res for res in results])\n",
    "    \n",
    "    if isSideways:\n",
    "        return []\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this, we'll define a couple more functions that will be useful when going through our pdfs page-by-page. `filterRes` in particular will help us on multiple occasions where we need to determine if a string matches certain characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets last line of string passed to it.\n",
    "def getLastLine(res):\n",
    "    try:\n",
    "        return res.split('\\n')[-2]\n",
    "    except:\n",
    "        return res.split('\\n')[-1]\n",
    "\n",
    "#Does res include at least one term from each list in 'includeSets'?\n",
    "#Does it also not contain any terms from any list in 'excludeSets'?\n",
    "def filterRes(res, includeSets, excludeSets):\n",
    "    includeVals = []\n",
    "    \n",
    "    for termList in includeSets:\n",
    "        includeVals.append(\n",
    "            any([re.search(term, res, re.IGNORECASE)\n",
    "                 for term in termList])\n",
    "        )\n",
    "        \n",
    "    excludeVals = []\n",
    "    \n",
    "    for termList in excludeSets:\n",
    "        excludeVals.append(\n",
    "            any([re.search(term, res, re.IGNORECASE)\n",
    "                 for term in termList])\n",
    "        )\n",
    "       \n",
    "    return (all(includeVals) and not any(excludeVals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still need to narrow our search a bit to ensure that we generally receive 1 table per pdf. To do this, we'll make sure that the table includes the name of at least 1 export ('bannanas, 'obacco' (the pdf parser occasionally confuses 'tobacco' with 'obacco'), 'copper', 'hide', and 'kola'). We'll also make sure that it's not an unrelated table being confused with a pdf table by excluding certain terms: by excluding 'ales' and 'cigar', we ensure that no import tables slip through the cracks; by excluding 'tariff', we filter out tarriff tables; 'seiz' excludes tables enumerating property confiscated by colonial authorities.\n",
    "\n",
    "Lastly, before we begin our search, we'll need to separate tables which are separated by a single paragraph. Let's make a regex to identify long lines of text separated by single spaces. This particular regex needed to be tailored to a surprising degree of specificity to meet all relevant cases, so I won't walk through each component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "expList = ['bananas', 'obacco', 'copper', 'hide', 'kola']\n",
    "termsToExclude = ['tariff', 'ales', 'cigar', 'seiz']\n",
    "\n",
    "#A line with single spaces that does not contain 'tobacco', because there's\n",
    "#one line containing 'tobacco' which would break this otherwise.\n",
    "singSpaceLineRgx = '((?!Tobacco)^ *(?:[^ \\n]+ [^ \\n]){5,}(?:(?!  ).)* *$)+'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've developed a robust set of criteria to identify and isolate export tables, let's loop through each page of each pdf and find the export tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "expTabsRaw = { pdf: [] for pdf in texts }\n",
    "\n",
    "for pdf, textList in texts.items():\n",
    "    skipNext = 0\n",
    "    processedPages = set()\n",
    "    \n",
    "    for page, pgText in enumerate(textList):\n",
    "        #If the last loop already parsed this page.\n",
    "        if page in processedPages:\n",
    "            continue\n",
    "        \n",
    "        results = getExportPage(pgText, expTabRgx1, \n",
    "                                expTabRgx2)\n",
    "\n",
    "        for res in results:\n",
    "            #If the last line is a table line, the table will continue to next page.\n",
    "            #In that case, add the next page's content to this page and parse as single table.\n",
    "            lastLine = getLastLine(res)\n",
    "\n",
    "            if re.search(tableRgx, lastLine):\n",
    "                try:    \n",
    "                    res = res + textList[page + 1]\n",
    "                    processedPages.add(page + 1)\n",
    "                    \n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            cleanRes = re.sub('\\n{2,}', '\\n', res)\n",
    "\n",
    "            tableRes = [res[0] for res in \n",
    "                        re.findall(tableRgx, cleanRes)]\n",
    "            \n",
    "            for tabInd, tab in enumerate(tableRes):\n",
    "                #Split by any line that seems like paragraph text rather than table text.\n",
    "                splitTabs = re.split(singSpaceLineRgx, tab, flags = re.M)\n",
    "                \n",
    "                for table in splitTabs:\n",
    "                    meetsReqs = filterRes(table, includeSets = [expList],\n",
    "                                          excludeSets = [termsToExclude])\n",
    "                    \n",
    "                    if meetsReqs:\n",
    "                        expTabsRaw[pdf].append(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Narrowing Result Set\n",
    "\n",
    "Now that we've extracted export tables, let's evaluate the performance of our script. For what number of pdfs have we succesfully extracted tables? How many pdfs have no or multiple tables? Have we truncated any of these tables or collected unnecessary data surrounding them?\n",
    "\n",
    "The first day of this project was essentially a cycle of gradually revising the export-table-extraction script and subsequently consulting the output of this cell. The goal was to minimize tables-per-pdf (such that each pdf hopefully had only one export table) while maximizing the number of pdfs with tables (such that as many pdfs as possible had export tables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tThere are 42 pdfs for which we found multiple results.\n",
      "\tThere are 6 pdfs for which we found a single result.\n",
      "\tThere are 0 pdfs for which we found no results.\n"
     ]
    }
   ],
   "source": [
    "from operator import gt, eq, lt\n",
    "\n",
    "#Returns list of tablists for which the length\n",
    "#fulfills the specified 'comp' operation (e.g. 'gt')\n",
    "# against the 'length' param.\n",
    "def searchTabByLen(tabDict, comp, length):\n",
    "    return [pdf for pdf, tabList\n",
    "            in tabDict.items() \n",
    "            if comp(len(tabList), length)]\n",
    "\n",
    "#How many tables sets in result have a single, multiple, or no tables?\n",
    "def evaluateTables(tabDict):\n",
    "    print('\\tThere are %d pdfs for which we found multiple results.'\n",
    "          % len(searchTabByLen(tabDict, gt, 1)))\n",
    "    print('\\tThere are %d pdfs for which we found a single result.'\n",
    "          % len(searchTabByLen(tabDict, eq, 1)))\n",
    "    print('\\tThere are %d pdfs for which we found no results.'\n",
    "          % len(searchTabByLen(tabDict, lt, 1)))\n",
    "    \n",
    "evaluateTables(expTabsRaw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we need to trim down our result set a bit, such that each pdf has only a single result set. After a few hours experimenting with various criteria, I ascertained a relatively effective list. We will be sure to implement more lenient requirements for result sets with only a single table candidate, of course, to avoid depopulating results sets that already have one table. \n",
    "\n",
    "Our criteria function to prioritize results which contains units commonly used in export tables (e.g. 'value', 'ton', etc.) and deprioritize terms pertaining to country names. The latter serves to filter out tables which list exports on a country-by-country basis in favor of those which list only commodities and values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tThere are 3 pdfs for which we found multiple results.\n",
      "\tThere are 45 pdfs for which we found a single result.\n",
      "\tThere are 0 pdfs for which we found no results.\n"
     ]
    }
   ],
   "source": [
    "expTabsCut = { pdf : [] for pdf in expTabsRaw }\n",
    "\n",
    "yearsListRgx = '((19[0-9b ]{2}).{0,2}[\\s]+){2,}'\n",
    "yearsList = [yearsListRgx]\n",
    "valueTerms = ['value', '£', 'ton']\n",
    "countryTerms = ['countries', 'union', 'united', 'victoria']\n",
    "    \n",
    "for pdf, arr in expTabsRaw.items(): \n",
    "    numTabs = len(arr)\n",
    "    \n",
    "    for tab in arr:\n",
    "        #Requirements for a duplicate table to be included in reduced array.\n",
    "        meetsReqsForDup = filterRes(tab, includeSets = [yearsList, valueTerms],\n",
    "                                excludeSets = [countryTerms, ['\\(b\\) Re-exports']])\n",
    "        \n",
    "        if numTabs == 1 or meetsReqsForDup:\n",
    "            expTabsCut[pdf].append(tab)\n",
    "        \n",
    "        else:\n",
    "            numTabs -= 1\n",
    "            \n",
    "evaluateTables(expTabsCut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After investigating the 3 remaining pdfs, I found a heuristic for which we can easily remove table sets with multiple entries; if an array has multiple entries, it is because one lists items in tons while the other lists them in monetary values. As a result, we can achieve optimal results by simply prioritizing results that don't use tonnage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tThere are 0 pdfs for which we found multiple results.\n",
      "\tThere are 48 pdfs for which we found a single result.\n",
      "\tThere are 0 pdfs for which we found no results.\n"
     ]
    }
   ],
   "source": [
    "#Takes an array, removes entry which lists exports in tonnage if array has multiple entries.\n",
    "def removeTonnage(arr, pdf):\n",
    "    revisedArr = []\n",
    "    listLen = len(arr)\n",
    "    \n",
    "    if listLen == 1:\n",
    "        return arr\n",
    "\n",
    "    for tab in arr:\n",
    "        #Make sure that we don't eradicate single-el lists.\n",
    "        if not 'ton' in tab.lower() or listLen == 1:\n",
    "            revisedArr.append(tab)\n",
    "        else:\n",
    "            listLen -= 1\n",
    "        \n",
    "    return revisedArr\n",
    "\n",
    "expTabs = {pdf : removeTonnage(arr, pdf)[0] for\n",
    "           pdf, arr in expTabsCut.items()}\n",
    "\n",
    "#searchTabByLen assumes that each pdf will have a list of tables.\n",
    "#So, for evaluateTables to work, we have to restructure it.\n",
    "#We're still gonna use expTabs for data operations, obviously.\n",
    "reworkedExpTabs = { pdf : [tab] for pdf, tab in expTabs.items() }\n",
    "evaluateTables(reworkedExpTabs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've adequately narrowed our results set, let's take a look at our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b31409350.pdf:\n",
      "\n",
      "                                              1937•                       1938.\n",
      "                                    Amount.           Value.      Amount.       Value.\n",
      "                                                        £                         £\n",
      "Chillies and capsicums        lb.       3,°77               38       9,091          114\n",
      "Coffee ...       ...  ...    cwt.         908            2,051         251          587\n",
      "Maize and maize flour         lb.   iji7I»o°5            1,307     161,041          180\n",
      "Rice ...                                1,235                6     115,801          517\n",
      "Tobacco:—\n",
      "  leaf dark-fired     ...     ,,    7,013,224         204,552     6,130,539    178,802\n",
      "    ,, flue-cured                   1,230,824          35,899     1,241,972     36,224\n",
      "    ,, air-cured      ...     ,,      746,274          21,766     1,858,129     54,195\n",
      "  strips dark fired ...       ,,    4,384,886         127,893     3,05U770      89,010\n",
      "      ,,   flue-cured ...     ,,      646,081          18,844       506,715     14,779\n",
      "      ,,   air-cured  ...     ,,      515,644          15,040       674,518     19,673\n",
      "Tea\n",
      "  Oj     •••     •••  •••     y y   8,816,788         326,048    10,218,821    448,477\n",
      "Grape Fruit ...                        —                 —            38,438       323\n",
      "Beeswax          ...  ...      ,,      35,805           1,492         14,625       609\n",
      "Cotton (lint) ...      ...   tons       2,066         105,722          3,060    99,953\n",
      "Cotton seed ...        ...     ,,         895           2,440            675     1,688\n",
      "Fibre of all kinds    ...     lb.   1,968,345          12,900       293,953      1,575\n",
      "Groundnuts ...         ...   tons      —                 —               278      1,724\n",
      "Potatoes         ...   ...    lb.      39,588              159        50,063        201\n",
      "Soya beans                             —                 —           476,956        806\n",
      "Rubber            ...  ...     ,,     203,175            3,449       159,165      3,316\n",
      "Strophanthus...        ...     ,,      24,674            2,467        20,825      2,082\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "\n",
      "b31411514.pdf:\n",
      "\n",
      "                                                              1937’                         1938.\n",
      "                     Article.\n",
      "                                                  Quantity.           Value.     Quantity.          Value.\n",
      "             Domestic Exports.\n",
      "  Class      I.—Food, Drink AND                                         £                             £\n",
      "                   Tobacco.\n",
      "Cocoa                                  Tons         3,667         95,523          5,789         79,693\n",
      "Coffee—raw                             Tons           123          4,722             17            467\n",
      "Grain :—\n",
      "  Maize                                Tons               1               6             4                 37\n",
      "  Other kinds                          Tons               4              67             5                 87\n",
      "Nuts and kernels :—\n",
      "  Kola nuts                            Tons              82             978         155             1,825\n",
      "  Other kinds                          Tons               6              64         —                   6\n",
      "Salt                                   Tons               5              37             5              34\n",
      "Other Food and Drink ...                 •••         —                   90         —                  81\n",
      "             Total Class I               •••          —          101,487            —           82,230\n",
      "\f",
      "                                       23\n",
      "                                                 *937•                      1938.\n",
      "               Article.\n",
      "                                      Quantity.      Value.      Quantity.      Value.\n",
      "                                                          £                          £\n",
      "  Class II.—Raw Materials\n",
      "    and Articles mainly\n",
      "        Unmanufactured.\n",
      "Cotton—raw       . Tons                     78                          2                29\n",
      "                                                          857\n",
      "Nuts and kernels for expressing\n",
      "    oil therefrom:—\n",
      "  Palm kernels ...     ... Tons             90            762        72              586\n",
      "Other Raw Materials, etc.                                 569                        455\n",
      "          Total Class II ...             -—.             2,188      —               1,070\n",
      "Class   III.—Articles       wholly\n",
      "  or mainly Manufactured.\n",
      "Cotton piece goods (native\n",
      "  manufacture).       ... Sq. yd.      2,074               198\n",
      "                            Cwt.          72\n",
      "Wood and Timber manufactured                               42       —                123\n",
      "Other articles                                            569                        501\n",
      "          Total Class III ...            —                809       —                624\n",
      "Class IV.—Animals not           for\n",
      "  Food   .                      No.         54              11                           3\n",
      "                                                                     *7\n",
      "          Total Domestic Exports         —         104,495          —          83.927\n",
      "                                                                                ■—\n",
      "            Re-Exports.\n",
      "             Class   III.\n",
      " Articles wholly          or mainly\n",
      "         Manufactured.\n",
      "C.—Miscellaneous                         —               7^64       —           3.048\n",
      "        Total Re-Exports                 —               7.364      —           3.048\n",
      "Grand total Exports (exclusive of\n",
      "  Specie and Currency Notes) ...         —         iii,859          —          86,975\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "\n",
      "b31409106.pdf:\n",
      "\n",
      "                           1933-    ^934-    1935-    1936.    1937-\n",
      "                           Tons.    Tons.    Tons.    Tons.    Tons.\n",
      "   Bananas (dried)   ...     533      537      740      455      630\n",
      "   Bananas (fresh)   ...   16,789   22,781   37,752   49,605   55,737\n",
      "   Cocoa                    3,608    4,56i    4,073    4,774    4,796\n",
      "   Kola Nuts                 —        —        —        —\n",
      "   Palm Kernels             1,617    1,283    i,4l8    1,506    1,803\n",
      "   Palm Oil    ...          1,837    B477     i,73i    1,648    1,583\n",
      "   Rubber                    164      657      599      582       725\n",
      "   Wood and Timber          6,560    5,184    3,055    5T42     5,068\n",
      "   (unmanufactured).\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DIVIDER = '\\n----------------------------------------------------------------------------------------------------------\\n'\n",
    "\n",
    "for pdf, tab in list(expTabs.items())[:3]:\n",
    "    print(pdf + ':')\n",
    "    print(tab + DIVIDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing Tables\n",
    "\n",
    "There are two basic types of tables in our results set, each of which must be parsed using a different method. Note that we won't get 100% accuracy with our parsing methods; even with 70 or 80%, we've still substantially expedited our data extraction process.\n",
    "\n",
    "Below are some examples of each table type.\n",
    "\n",
    "#### TABLE TYPE 0:\n",
    "```\n",
    "                            Slaughter Stock.\n",
    "            1932.      1933-          1934*           1935-              1936.\n",
    "   lb.   5,338,800   9,600,000      6,079,400       5,747,400          8,620,000\n",
    "   £        23,728      62,400         40,536          38,316             57,468\n",
    "                                  Tobacco.\n",
    "   lb.    341.055     377,906         374,952            261,794        282,735\n",
    "   £       10,850      10,010          10,433              6,542          9,44i\n",
    "                             Cotton {Seed).\n",
    "   lb.    750,000     207,000         295,800            200,068        124,750\n",
    "   £        3.125       1,400           2,048              i,459            950\n",
    "                            Hides and Skins.\n",
    "   lb.     60,750     439,820         451,850            496,471        600,000\n",
    "              633       5,910           6,200              8,449         15,000\n",
    "   £\n",
    "                                 Wattle Bark.\n",
    "   lb.      56,000   1,322,000        300,000            939,200        598,080\n",
    "   £            28       2,653            536              1,825          U335\n",
    "\f",
    "12                    COLONIAL REPORTS—ANNUAL\n",
    "                                      Wool.\n",
    "     lb.   30,000        17,138           18,638         20,000       22,000\n",
    "     £        490           533              536            750          825\n",
    "                                      Butter.\n",
    "     lb.     1 >705        1,210           1,500             3,202     —\n",
    "     £           85           61              68               199     —\n",
    "                                   Butter-Fat.\n",
    "     lb.    22,197       86,690           27,348         21,139       68,000\n",
    "     £         740        3>973            1,004            856        3,825\n",
    "                                     Bullion.\n",
    "     £       1,542         3,9i4           2,608             2,130     3,866\n",
    "                                   Metallic Tin.                        -\n",
    "     lb.   187,980     226,912           362,380        406,963      409,248\n",
    "     £      J1>497      19,665            37,356         39,628       39,35i\n",
    "```\n",
    "\n",
    "#### TABLE TYPE 1:\n",
    "\n",
    "```\n",
    "                                           1931.                         1932.\n",
    "            Article.              Value.           Per cent.   Value.            Per cent,\n",
    "                                    £                             £\n",
    "Sisal ...     .            ...   707,177            43-0       698,202            31-9\n",
    "Cotton        .            ...   119,752             7-3       183,747             8-4\n",
    "Groundnuts                        28,706             1-7       182,010             8-3\n",
    "Coffee ...                 ...   247,037            15-0       463,597            21-2\n",
    "Hides and skins                   83,915             51         99,474             4-5\n",
    "Copra ...                         62,209             3-8        64,694             2-9\n",
    "Grain, other than rice            34,547             21         34,600             1*6\n",
    "Sesame                            36,715             2-2        50,130             2-3\n",
    "Beeswax                           47,010             2-9        31,965             1-4\n",
    "Ghee.                ,..          11,549             0-7        16,848             0-8\n",
    "Rice ...                          51,209             31         62,939             2-9\n",
    "```\n",
    "\n",
    "```\n",
    "                                Principal Domestic Exports.\n",
    "           Article.                 1913.         1929.       1930.      1931.       1932.\n",
    "Sisal                   tons        20,834       45,728      49,962     55,939      60,554\n",
    "Groundnuts               99          8,961        7,765      17,333      3,070      15,873\n",
    "Coffee                    99         1,059        8,857      11,547      9,251      11,362\n",
    "Cotton ...            centals       49,101      110,821      82,224     54,349      71,888\n",
    "Copra                   tons         5,477        7,920        7,395     7,234       7,265\n",
    "Hides and skins           99         3,456        2,549        2,094     2,111       2,718\n",
    "Grain                   cwt.        44,640      160,924     143,912    260,099     268,135\n",
    "Sesame ...              tons         1,476        4,256       3,115      3,825       4,811\n",
    "Beeswax                  99            559          336          189       607         391\n",
    "Ghee                    cwt.         6,760        9,073       5,860      5,862       7,172\n",
    "Soap                     99\n",
    "                                      —             130          981       316         469\n",
    "Salt                    tons          —           2,999       3,046      2,963       2,428\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "Fortunately, all tables of Type 0 contain the term `slaughter`, so it's relatively simple to disaggregate the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "\n",
    "#Disaggregates tables into 2 table formats in pdf set.\n",
    "def tableKeyFunc(tab):\n",
    "    tabLow = tab[1].lower()\n",
    "    \n",
    "    if 'slaughter' in tabLow: \n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "groupTabs = groupby(\n",
    "                sorted(expTabs.items(), key = tableKeyFunc), \n",
    "                tableKeyFunc\n",
    "            )\n",
    "\n",
    "type0Tabs, type1Tabs = [dict(group) for _, group in groupTabs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're almost ready to loop through each of our two table lists (`type0Tabs` and `type1Tabs`), but, first, let's define a data structure to simplify inserts into a multi-dimensional dict and another function that will be helpful in the table-parsing process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "#Creates a dictionary of depth n to hold instances of given type.\n",
    "def nestedDict(n, type):\n",
    "    if n == 1: \n",
    "        return defaultdict(type)\n",
    "    return defaultdict(lambda: nestedDict(n - 1, type))\n",
    "\n",
    "#Removes prefix from start of string.\n",
    "def removePrefix(string, prefix):\n",
    "    if string.startswith(prefix):\n",
    "        return string[len(prefix):]\n",
    "    return string[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can parse the type 0 tables. This relatively simple table structure (particularly compared to type 1) with a low degree of diversity between tables in the set, so the cell below doesn't warrant an in-depth explanation. Essentially, we identify the list of years, identify the exports, and go through numerical values row-by-row basis, entering them into a dictionary based on the last export header and the relevant years column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final data structure.\n",
    "masterExpDict = {}\n",
    "\n",
    "for pdf, tab in type0Tabs.items():\n",
    "    header = None\n",
    "    lineNo = 0\n",
    "    \n",
    "    lines = re.split('\\n+', tab)\n",
    "    #Get rid of whitespace at start of line.\n",
    "    cleanLines = [line.strip() for line in lines]\n",
    "    yearsLine = [line for line in cleanLines if \n",
    "                 re.search(yearRgx, line)]\n",
    "    \n",
    "    years = yearsLine[0].split()\n",
    "    \n",
    "    #Filter out any titles grabbed when crossing pages.\n",
    "    #Also filter out any lines listing years.\n",
    "    filteredLines = filter(lambda line: not (\n",
    "                            'COLONIAL' in line\n",
    "                            or 'WAGES' in line\n",
    "                            or re.search(yearRgx, line)\n",
    "                        ),\n",
    "                      cleanLines)\n",
    "    #Facilitates format data[export][year][unit].\n",
    "    data = nestedDict(3, str)\n",
    "    \n",
    "    for line in filteredLines:\n",
    "        hasLbs = line.startswith('lb.')\n",
    "        hasDigit = re.search('\\d', line)\n",
    "        \n",
    "        #If no digits and no 'lb.', it's a header.\n",
    "        if not hasLbs and not hasDigit:\n",
    "            #Grab up until first period.\n",
    "            export = line.split('.', 1)[0]\n",
    "            lineNo = 0\n",
    "            continue\n",
    "        \n",
    "        lineNo += 1\n",
    "        \n",
    "        #1st line after header (the name of export) has lb vals, 2nd has £s.\n",
    "        pound = 'lb.' if lineNo == 1 else '£'\n",
    "        withoutPound = removePrefix(line, pound)\n",
    "        splitBySpace = withoutPound.split()\n",
    "\n",
    "        for year, val in zip(years, splitBySpace):\n",
    "            data[export][year][pound] = val\n",
    "    \n",
    "    masterExpDict[pdf] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure of type 1 tables is far more complex by comparison. In some instances, table headers contain no units (as in Ex. 1) in the header, and, in some instance, they contain multiple units (as in Ex. 2). As a result, our parsing script must prioritize identification of the list of years and list of units within the table header, and the relevant regexes are shown below.\n",
    "\n",
    "#### EX. 1:\n",
    "\n",
    "```\n",
    "      Commodity.          Unit.     1913.         1930.      1931.       1932.       1933.\n",
    "Sisal                ..    ton      20,834        49,962     55,939      60,554      69,600\n",
    "Coffee               ••     »        1,059        11,547      9,251      11,362      12,718\n",
    "Cotton ...           ..cental       49,101        82,224     54,349      71,888     113,677\n",
    "Gold                  oz. troy      10,032        12,971     15,200      31,030      38,704\n",
    "Groundnuts           ..   ton        8,961        17,333      3,070      15,873      19,177\n",
    "Hides and skins             99       3,456         2,094      2,111       2,718       4,140\n",
    "\f",
    "                                            50\n",
    "   Commodity.      Unit.      1913.          1930.            1931.        1932.      1933.\n",
    "Grain               cwt.      44,640        143,912      260,099        268,135       222,658\n",
    "Copra               ton        5,477          7,395        7,234          7,265         8,157\n",
    "Beeswax              99          559            189          607            391           680\n",
    "Ghee                cwt.       6,760          5,860        5,862          7,172         9,604\n",
    "Sesame ...          ton        1,476          3,115        3,825          4,811         4,441\n",
    "Ivory               cwt.         212            256          354            517           467\n",
    "```\n",
    "\n",
    "#### EX. 2:\n",
    "\n",
    "```\n",
    "                                    1931.                 1932.                    1933.\n",
    "      Commodity.           Value.     Per cent.      Value.    Per cent.     Value.    Per cent.\n",
    "                              £                      £                         £\n",
    "Sisal                      707,177      43-0      698,202        31-9       881,772        34-7\n",
    "Coffee.                    247,037      15-0      463,597        21-2       429,523        16-9\n",
    "Cotton ...                 119,752       7-3      183,747         8-4       276,864        10-9\n",
    "Gold   .                    60,183       3-7      157,726         7-2       195,369         7-7\n",
    "Groundnuts                  28,706       1-7      182,010         8-3       166,223         6-5\n",
    "Hides and skins             83,915       5-1       99,474         4-5       165,382         6-5\n",
    "Rice                        51,209       3-1       62,939         2-9        62,382         2-5\n",
    "Copra ...                   62,209       3-8       64,694         2-9        62,160         2-4\n",
    "Beeswax                     47,010       2-9       31,965         1-4        52,751         21\n",
    "Sesame                      36,715       2-2       50,130         2-3        41,845         1-6\n",
    "Ghee   .                    11,549       0-7       16,848         0-8        19,586         0-8\n",
    "Grain, other than rice      34,547       2-1       34,600         1-6        17,763         0-7\n",
    "Ivory ...            ...    13,504       0-8       20,577         0-9        13,753         0-5\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PDF data reader does worse with type 2, so we use more general rgx.\n",
    "yearsRgx = '((19[0-9b ]{2}).+[\\s]+.+)+'\n",
    "\n",
    "#Rgx for numbers with commas separated by a single space.\n",
    "#Also accounts for various parser misreadings of digits.\n",
    "spaceSepNums = '([\\d,*’SI-]+ ?)+'\n",
    "\n",
    "#Rgx for units of cells at head of table.\n",
    "unitRgx = '(.+(Amount|Quantity|Tons|Value|£).+\\n?)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explaining our entire method for parsing type1 tables would be extremely prolix, so we'll avoid delving into cases where we handle exceptions which encompass only 1 or 2 pdfs. Essentially, I parsed type 1 tables as follows:\n",
    "\n",
    "- 1) Identify the list of years and the list of units.\n",
    "- 2) Identify the ratio between the list of years and the list of units.\n",
    "- 3) Determine from this ratio the relevant structure of the table; for ex. 2 above, for instance, we would generate the structure with the `grouper` function and receive a value of `[(1931, 'Value'), (1931, 'Per cent'), (1932, 'Value'), (1932, 'Per cent')]`.\n",
    "- 4) Parse the cells of each row, delimited by spaces, right-to-left; right-to-left parsing ensures that we don't interpret noise between the export name and numerical values as data points.\n",
    "- 5) Store in a master data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tb31409386.pdf failed\n"
     ]
    }
   ],
   "source": [
    "from itertools import zip_longest\n",
    "\n",
    "#Split array into arrays of length N.\n",
    "def grouper(iterable, n, fillvalue = None):\n",
    "    # grouper('ABCDEFG', 3, 'x') --> ABC DEF Gxx\n",
    "    args = [iter(iterable)] * n\n",
    "    return zip_longest(fillvalue = fillvalue, *args)\n",
    "\n",
    "for pdf, tab in type1Tabs.items():\n",
    "    #Get rid of ellipses or permutations of them caused by pdf reader.\n",
    "    noEllipse = re.sub('\\.\\.\\.|•••|,,', '', tab)\n",
    "    data = nestedDict(3, str)\n",
    "    splitLines = [line.rstrip() for line in\n",
    "                    re.split('\\n+', noEllipse)]\n",
    "    \n",
    "    try:\n",
    "        yearLines = [line for line in splitLines\n",
    "                    if re.search(yearsRgx, line)]\n",
    "        yearLine = yearLines[0]\n",
    "        \n",
    "        #Deal with specific case that breaks for some reason.\n",
    "        if '*934-       1935' in yearLine:\n",
    "            yearLine += yearLines[1]\n",
    "            \n",
    "        yearsClean = re.sub(r'(19) (\\d{2})', r'\\1\\2', yearLine)\n",
    "        \n",
    "        #Split by spaces, filter out non-numerical values.\n",
    "        years = [word for word in yearsClean.split()\n",
    "                 if re.search('\\d', word)]\n",
    "\n",
    "    except:\n",
    "        print('\\t' + pdf + ' failed')\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        unitLines = [res[0] for res in \n",
    "                     re.findall(unitRgx, tab)\n",
    "                     if not re.search('\\d', res[0])]\n",
    "        unitsRaw = max(unitLines, key = len)\n",
    "        unitsClean = unitsRaw.replace(\n",
    "                            'Per cent', 'Percent'\n",
    "                        ).replace('Per cei', 'Percent')\n",
    "        unitsFiltered = re.sub('Commodity|Article|,|\\.', '', unitsClean)\n",
    "        units = unitsFiltered.split()\n",
    "        \n",
    "    except:\n",
    "        units = []\n",
    "    \n",
    "    excRgxs = (['class'] if 'class' in res.lower()\n",
    "               else [yearsRgx, unitRgx]) \n",
    "    \n",
    "    filteredLines = filter(lambda res: filterRes(\n",
    "                                        res,\n",
    "                                        includeSets = [],\n",
    "                                        excludeSets = [excRgxs]\n",
    "                                       ),\n",
    "                           splitLines)\n",
    "    \n",
    "    rowsRaw = [item for item in \n",
    "                 [re.split(' {2,}', line.lstrip())\n",
    "                    for line in filteredLines]\n",
    "               if item != ['']]\n",
    "    rows = []\n",
    "    \n",
    "    alreadyProcessed = 0\n",
    "    \n",
    "    for rowInd, row in enumerate(rowsRaw):\n",
    "        allAlphabetic = all([re.fullmatch('[a-zA-Z, ]+', item)\n",
    "                             for item in row])\n",
    "        \n",
    "        #Account for case where row is just a label, but there are multiple spaces between words\n",
    "        if allAlphabetic:\n",
    "            row = [' '.join(row)]\n",
    "        \n",
    "        if alreadyProcessed:\n",
    "            alreadyProcessed = 0\n",
    "            continue\n",
    "        \n",
    "        #Those that start in lowercase are subcategories of another export.\n",
    "        if not row[0].islower():\n",
    "            lastCapital = row[0]\n",
    "        #We gotta account for the one exception where the first char of each row got cut off.\n",
    "        elif pdf != 'b31411101.pdf':\n",
    "            row[0] = lastCapital + ' ' + row[0]\n",
    "        \n",
    "        #If row only consists of numerical data, it's the result of the previous row getting bifurcated.\n",
    "        if re.fullmatch('[\\d, —]+', ''.join(row)):\n",
    "            numbers = [cell for cell in row \n",
    "                       if re.search('[\\d,]+', cell)]\n",
    "            row = rowsRaw[rowInd - 1] + numbers\n",
    "            \n",
    "        #Non-empty elements of row.\n",
    "        filteredList = list(filter(bool, row))\n",
    "        cleanList = []\n",
    "        \n",
    "        for item in filteredList:\n",
    "            #We can get cases where numbers separated by a single space are read as one cell.\n",
    "            #Here, we split them apart to prevent that.\n",
    "            if re.fullmatch(spaceSepNums, item):\n",
    "                cleanList.extend(item.split(' '))\n",
    "                \n",
    "            #If there's just one item in the row, don't bother with it.\n",
    "            elif len(filteredList) != 1:\n",
    "                cleanList.append(item)\n",
    "            \n",
    "        rows.append(cleanList)\n",
    "\n",
    "    for ind, row in enumerate(rows):\n",
    "        #If row has only one cell, merge with next row\n",
    "        try:\n",
    "            if len(row) == 1 and row[0] != '':\n",
    "                firstNonEmptyInd = [i for i, v in \n",
    "                                    enumerate(rows[ind + 1])\n",
    "                                    if v != ''][0]\n",
    "\n",
    "                currentVal = rows[ind + 1][firstNonEmptyInd]\n",
    "                rows[ind + 1][firstNonEmptyInd] = row[0] + currentVal\n",
    "        \n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    #Generate hierarchical structure of table headers.\n",
    "    #I explain in the previous markdown cell.\n",
    "    unitYearRatio = int(len(units) / len(years))\n",
    "    groupedUnits = list(grouper(units, unitYearRatio))\n",
    "    revGroupedUnits = list(map(reversed, groupedUnits))\n",
    "    \n",
    "    if not revGroupedUnits:\n",
    "        revGroupedUnits = ['£'] * len(years)\n",
    "    \n",
    "    #There's usually noise between the export label and values, so we go right-to-left.\n",
    "    yearUnitZip = zip(reversed(years), revGroupedUnits)\n",
    "    yearUnitPairs = []\n",
    "    \n",
    "    for year, unitList in yearUnitZip:\n",
    "        yearUnitTups = [(year, unit) for unit in unitList]\n",
    "        \n",
    "        for tup in yearUnitTups:\n",
    "            yearUnitPairs.append(tup)\n",
    "    \n",
    "    for row in rows:        \n",
    "        try:\n",
    "            export = [cell for cell in row if\n",
    "                      re.search('[a-zA-Z]{2,}', cell)][0]\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        for cellInd, cell in enumerate(reversed(row)):\n",
    "            try:\n",
    "                year, unit = yearUnitPairs[cellInd]\n",
    "                data[export][year][unit] = cell\n",
    "            \n",
    "            except IndexError:\n",
    "                continue\n",
    "\n",
    "    masterExpDict[pdf] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA REVIEW:\n",
    "\n",
    "Let's take a look at the data we have so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b31408990.pdf\n",
      "\tSlaughter Cattle\n",
      "\t\t1928.\n",
      "\t\t\tlb. : 3,639,600\n",
      "\t\t\t£ : 54,594\n",
      "\t\t1929.\n",
      "\t\t\tlb. : 5,500,000\n",
      "\t\t\t£ : 85,000\n",
      "\t\t1930.\n",
      "\t\t\tlb. : 4,373,700\n",
      "\t\t\t£ : 50,763\n",
      "\t\t1931.\n",
      "\t\t\tlb. : 5,181,600\n",
      "\t\t\t£ : 33,322\n",
      "\t\t1932.\n",
      "\t\t\tlb. : 5,338,800\n",
      "\t\t\t£ : 23,728\n",
      "\tTobacco\n",
      "\t\t1928.\n",
      "\t\t\tlb. : 1,283,250\n",
      "\t\t\t£ : 37,428\n",
      "\t\t1929.\n",
      "\t\t\tlb. : 1,068,400\n",
      "\t\t\t£ : 35,613\n",
      "\t\t1930.\n",
      "\t\t\tlb. : 578,330\n",
      "\t\t\t£ : 14,397\n",
      "\t\t1931.\n",
      "\t\t\tlb. : 298,413\n",
      "\t\t\t£ : 9,082\n",
      "\t\t1932.\n",
      "\t\t\tlb. : 341,055\n",
      "\t\t\t£ : 10,850\n",
      "\tCotton (Seed)\n",
      "\t\t1928.\n",
      "\t\t\tlb. : 850,814\n",
      "\t\t\t£ : 13,785\n",
      "\t\t1929.\n",
      "\t\t\tlb. : 2,618.913\n",
      "\t\t\t£ : 37,961\n",
      "\t\t1930.\n",
      "\t\t\tlb. : 3,224,182\n",
      "\t\t\t£ : 26,868\n",
      "\t\t1931.\n",
      "\t\t\tlb. : 1,532,132\n",
      "\t\t\t£ : 9,578\n",
      "\t\t1932.\n",
      "\t\t\tlb. : 750,000\n",
      "\t\t\t£ : 3,125\n",
      "\tHides\n",
      "\t\t1928.\n",
      "\t\t\tlb. : 368,400\n",
      "\t\t\t£ : 13,047\n",
      "\t\t1929.\n",
      "\t\t\tlb. : 434,840\n",
      "\t\t\t£ : 7,250\n",
      "\t\t1930.\n",
      "\t\t\tlb. : 208,140\n",
      "\t\t\t£ : 3,469\n",
      "\t\t1931.\n",
      "\t\t\tlb. : 143,600\n",
      "\t\t\t£ : 1,589\n",
      "\t\t1932.\n",
      "\t\t\tlb. : 60,750\n",
      "\t\t\t£ : 633\n",
      "\tSkins\n",
      "\t\t1928.\n",
      "\t\t\tlb. : —\n",
      "\t\t\t£ : —\n",
      "\t\t1929.\n",
      "\t\t\tlb. : —\n",
      "\t\t\t£ : —\n",
      "\t\t1930.\n",
      "\t\t\tlb. : —\n",
      "\t\t\t£ : —\n",
      "\t\t1931.\n",
      "\t\t\tlb. : 5,590\n",
      "\t\t\t£ : 144\n",
      "\t\t1932.\n",
      "\t\t\tlb. : —\n",
      "\t\t\t£ : —\n",
      "\tWattle Bark\n",
      "\t\t1928.\n",
      "\t\t\tlb. : 1,239,000\n",
      "\t\t\t£ : 4,920\n",
      "\t\t1929.\n",
      "\t\t\tlb. : —\n",
      "\t\t\t£ : 9,108\n",
      "\t\t1930.\n",
      "\t\t\tlb. : 2,274,500\n",
      "\t\t\t£ : 37\n",
      "\t\t1931.\n",
      "\t\t\tlb. : 9,000\n",
      "\t\t\t£ : 28\n",
      "\t\t1932.\n",
      "\t\t\tlb. : 56,000\n",
      "\tWool\n",
      "\t\t1928.\n",
      "\t\t\tlb. : 9,600\n",
      "\t\t\t£ : 400\n",
      "\t\t1929.\n",
      "\t\t\tlb. : 3,600\n",
      "\t\t\t£ : 150\n",
      "\t\t1930.\n",
      "\t\t\tlb. : 27,091\n",
      "\t\t\t£ : 909\n",
      "\t\t1931.\n",
      "\t\t\tlb. : 72,134\n",
      "\t\t\t£ : 1,636\n",
      "\t\t1932.\n",
      "\t\t\tlb. : 30,000\n",
      "\t\t\t£ : 490\n",
      "\tButter\n",
      "\t\t1928.\n",
      "\t\t\tlb. : 8,400\n",
      "\t\t\t£ : 420\n",
      "\t\t1929.\n",
      "\t\t\tlb. : —\n",
      "\t\t\t£ : —\n",
      "\t\t1930.\n",
      "\t\t\t£ : 130\n",
      "\t\t1931.\n",
      "\t\t\t£ : 52\n",
      "\t\t1932.\n",
      "\t\t\t£ : 855\n",
      "\tButter Fat\n",
      "\t\t1928.\n",
      "\t\t\tlb. : 1,800\n",
      "\t\t\t£ : 90\n",
      "\t\t1929.\n",
      "\t\t\tlb. : 4,400\n",
      "\t\t\t£ : 220\n",
      "\t\t1930.\n",
      "\t\t\tlb. : 33,870\n",
      "\t\t\t£ : 675\n",
      "\t\t1931.\n",
      "\t\t\tlb. : 21,670\n",
      "\t\t\t£ : 843\n",
      "\t\t1932.\n",
      "\t\t\tlb. : 22,197\n",
      "\t\t\t£ : 740\n",
      "\tBullion\n",
      "\t\t1928.\n",
      "\t\t\tlb. : Value\n",
      "\t\t1929.\n",
      "\t\t\tlb. : ...\n",
      "\t\t1930.\n",
      "\t\t\tlb. : £1,475\n",
      "\t\t1931.\n",
      "\t\t\tlb. : 382\n",
      "\t\t1932.\n",
      "\t\t\tlb. : Nil.\n",
      "\tMetallic Tin\n",
      "\t\t1928.\n",
      "\t\t\tlb. : 416,438\n",
      "\t\t\t£ : 39,706\n",
      "\t\t1929.\n",
      "\t\t\tlb. : 415,693\n",
      "\t\t\t£ : 38,692\n",
      "\t\t1930.\n",
      "\t\t\tlb. : 360,692\n",
      "\t\t\t£ : 23,414\n",
      "\t\t1931.\n",
      "\t\t\tlb. : 171,481\n",
      "\t\t\t£ : 8,875\n",
      "\t\t1932.\n",
      "\t\t\tlb. : 187,980\n",
      "\t\t\t£ : 11,497\n",
      "b31409052.pdf\n",
      "\t(Live Weight)\n",
      "\t\t1934-\n",
      "\t\t\tlb. : 6,079,400\n",
      "\t\t\t£ : 40,536\n",
      "\t\t1935-\n",
      "\t\t\tlb. : 5,747,400\n",
      "\t\t\t£ : 38,316\n",
      "\t\t1936.\n",
      "\t\t\tlb. : 8,620,000\n",
      "\t\t\t£ : 57,468\n",
      "\t\t1937-\n",
      "\t\t\tlb. : 8,010,900\n",
      "\t\t\t£ : 55,ooo\n",
      "\t\t1938.\n",
      "\t\t\tlb. : 6,346,000\n",
      "\t\t\t£ : 43,420\n",
      "\tTobacco\n",
      "\t\t1934-\n",
      "\t\t\tlb. : ft>.\n",
      "\t\t1935-\n",
      "\t\t\tlb. : 374,952\n",
      "\t\t1936.\n",
      "\t\t\tlb. : 261,794\n",
      "\t\t1937-\n",
      "\t\t\tlb. : 282,735\n",
      "\t\t1938.\n",
      "\t\t\tlb. : 200,789\n",
      "\tCotton [Seed)\n",
      "\t\t1934-\n",
      "\t\t\tlb. : 295,800\n",
      "\t\t\t£ : 2,048\n",
      "\t\t1935-\n",
      "\t\t\tlb. : 200,068\n",
      "\t\t\t£ : i,459\n",
      "\t\t1936.\n",
      "\t\t\tlb. : 124,750\n",
      "\t\t\t£ : 950\n",
      "\t\t1937-\n",
      "\t\t\tlb. : 103,550\n",
      "\t\t\t£ : 640\n",
      "\t\t1938.\n",
      "\t\t\tlb. : Nil.\n",
      "\t\t\t£ : Nil.\n",
      "\tHides and Skins\n",
      "\t\t1934-\n",
      "\t\t\tlb. : 45L850\n",
      "\t\t\t£ : 6,200\n",
      "\t\t1935-\n",
      "\t\t\tlb. : 496,471\n",
      "\t\t\t£ : 8,449\n",
      "\t\t1936.\n",
      "\t\t\tlb. : 600,000\n",
      "\t\t\t£ : 15,000\n",
      "\t\t1937-\n",
      "\t\t\tlb. : 537,6oo\n",
      "\t\t\t£ : 12,000\n",
      "\t\t1938.\n",
      "\t\t\tlb. : 264,32a\n",
      "\t\t\t£ : 5U32\n",
      "\tWattle Bark\n",
      "\t\t1934-\n",
      "\t\t\tlb. : 300,000\n",
      "\t\t\t£ : 536\n",
      "\t\t1935-\n",
      "\t\t\tlb. : 939,200\n",
      "\t\t\t£ : 1,825\n",
      "\t\t1936.\n",
      "\t\t\tlb. : 598,080\n",
      "\t\t\t£ : L335\n",
      "\t\t1937-\n",
      "\t\t\tlb. : 1,391,040\n",
      "\t\t\t£ : 4,002\n",
      "\t\t1938.\n",
      "\t\t\tlb. : 1,644,160\n",
      "\t\t\t£ : 4>n5\n",
      "\tWool\n",
      "\t\t1934-\n",
      "\t\t\tlb. : 18,638\n",
      "\t\t\t£ : 536\n",
      "\t\t1935-\n",
      "\t\t\tlb. : 20,000\n",
      "\t\t\t£ : 750\n",
      "\t\t1936.\n",
      "\t\t\tlb. : 22,000\n",
      "\t\t\t£ : 825\n",
      "\t\t1937-\n",
      "\t\t\tlb. : 10,000\n",
      "\t\t\t£ : 260\n",
      "\t\t1938.\n",
      "\t\t\tlb. : 25,000\n",
      "\t\t\t£ : 800\n",
      "\tButter-F at\n",
      "\t\t1934-\n",
      "\t\t\tlb. : 29,073\n",
      "\t\t\t£ : 1,072\n",
      "\t\t1935-\n",
      "\t\t\tlb. : 24,820\n",
      "\t\t\t£ : 1,055\n",
      "\t\t1936.\n",
      "\t\t\tlb. : 68,000\n",
      "\t\t\t£ : 3,825\n",
      "\t\t1937-\n",
      "\t\t\tlb. : 67,846\n",
      "\t\t\t£ : 3,474\n",
      "\t\t1938.\n",
      "\t\t\tlb. : 224,565\n",
      "\t\t\t£ : 11,763\n",
      "\tBullion\n",
      "\t\t1934-\n",
      "\t\t\tlb. : £\n",
      "\t\t1935-\n",
      "\t\t\tlb. : 2,608\n",
      "\t\t1936.\n",
      "\t\t\tlb. : 2,130\n",
      "\t\t1937-\n",
      "\t\t\tlb. : 3,866\n",
      "\t\t1938.\n",
      "\t\t\tlb. : 16,873\n",
      "\tMetallic Tin\n",
      "\t\t1934-\n",
      "\t\t\tlb. : 362,380\n",
      "\t\t\t£ : 37,356\n",
      "\t\t1935-\n",
      "\t\t\tlb. : 406,963\n",
      "\t\t\t£ : 39,628\n",
      "\t\t1936.\n",
      "\t\t\tlb. : 409,248\n",
      "\t\t\t£ : 39,35i\n",
      "\t\t1937-\n",
      "\t\t\tlb. : 345,945\n",
      "\t\t\t£ : 37U58\n",
      "\t\t1938.\n",
      "\t\t\tlb. : 389,536\n",
      "\t\t\t£ : 33>I29\n",
      "b31409003.pdf\n",
      "\t\n",
      "\t\tDecember,\n",
      "\t\t\tlb. : exported\n",
      "\t\t1933\n",
      "\t\t\tlb. : during\n",
      "\t\t:—\n",
      "\t\t\tlb. : the\n",
      "\tSlaughter Cattle\n",
      "\t\tDecember,\n",
      "\t\t\tlb. : 5,500,000\n",
      "\t\t\t£ : •••\n",
      "\t\t1933\n",
      "\t\t\tlb. : 4,373,700\n",
      "\t\t\t£ : 85,000\n",
      "\t\t:—\n",
      "\t\t\tlb. : 5,181,600\n",
      "\t\t\t£ : 50,763\n",
      "\tTobacco\n",
      "\t\tDecember,\n",
      "\t\t\tlb. : •••\n",
      "\t\t\t£ : ...\n",
      "\t\t1933\n",
      "\t\t\tlb. : 1,068,400\n",
      "\t\t\t£ : 35,613\n",
      "\t\t:—\n",
      "\t\t\tlb. : 578,330\n",
      "\t\t\t£ : 14,397\n",
      "\tCotton (Seed)\n",
      "\t\tDecember,\n",
      "\t\t\tlb. : 2,618.913\n",
      "\t\t\t£ : •••\n",
      "\t\t1933\n",
      "\t\t\tlb. : 3,224,182\n",
      "\t\t\t£ : 37,961\n",
      "\t\t:—\n",
      "\t\t\tlb. : 1,532,132\n",
      "\t\t\t£ : 26,868\n",
      "\tHides and Skins\n",
      "\t\tDecember,\n",
      "\t\t\tlb. : £\n",
      "\t\t1933\n",
      "\t\t\tlb. : ...\n",
      "\t\t:—\n",
      "\t\t\tlb. : 7,250\n",
      "\tWattle Bark\n",
      "\t\tDecember,\n",
      "\t\t\tlb. : 2,274,500\n",
      "\t\t\t£ : ...\n",
      "\t\t1933\n",
      "\t\t\tlb. : 9,000\n",
      "\t\t\t£ : —\n",
      "\t\t:—\n",
      "\t\t\tlb. : 56,000\n",
      "\t\t\t£ : 9,108\n",
      "\tWool\n",
      "\t\tDecember,\n",
      "\t\t\tlb. : 3,600\n",
      "\t\t\t£ : •••\n",
      "\t\t1933\n",
      "\t\t\tlb. : 27,091\n",
      "\t\t\t£ : 150\n",
      "\t\t:—\n",
      "\t\t\tlb. : 72,134\n",
      "\t\t\t£ : 909\n",
      "\tButter\n",
      "\t\tDecember,\n",
      "\t\t\tlb. : •••\n",
      "\t\t\t£ : •••\n",
      "\t\t1933\n",
      "\t\t\tlb. : 1,748\n",
      "\t\t\t£ : —\n",
      "\t\t:—\n",
      "\t\t\tlb. : 794\n",
      "\t\t\t£ : 130\n",
      "\tButter-Fat\n",
      "\t\tDecember,\n",
      "\t\t\tlb. : £\n",
      "\t\t1933\n",
      "\t\t\tlb. : ...\n",
      "\t\t:—\n",
      "\t\t\tlb. : 220\n",
      "\tBullion\n",
      "\t\tDecember,\n",
      "\t\t\tlb. : Value\n",
      "\t\t1933\n",
      "\t\t\tlb. : £\n",
      "\t\t:—\n",
      "\t\t\tlb. : 382\n",
      "\tMetallic Tin\n",
      "\t\tDecember,\n",
      "\t\t\tlb. : 415,693\n",
      "\t\t\t£ : •••\n",
      "\t\t1933\n",
      "\t\t\tlb. : 360,692\n",
      "\t\t\t£ : 38,692\n",
      "\t\t:—\n",
      "\t\t\tlb. : 171,481\n",
      "\t\t\t£ : 23,414\n"
     ]
    }
   ],
   "source": [
    "for pdf, exportDict in list(masterExpDict.items())[:3]:\n",
    "    print(pdf)\n",
    "    for export, dictionary in exportDict.items():\n",
    "        print('\\t' + export)\n",
    "        for year, values in dictionary.items():\n",
    "            print('\\t\\t' + year)\n",
    "            for unit, value in values.items():\n",
    "                print('\\t\\t\\t' + unit + ' : ' + value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a handful of errors and pdfs for which our script did not scale well. However, at this point, we seem to have hit a point of diminishing returns. It would be possible to code specific exceptions for each of the 3 or 4 cases which seem to break our rudimentary script, but it would be simpler and easier to do it by hand. Nonetheless, we have managed to reduce several weeks worth of transcription (further complicated by the hierarchical nature of the data, which disallows easy copying into a spreadsheet format) into a few days of code followed by a few hours of revisions (mainly corrected errors by the pdf reader). Given the failings of the pdf reader and diversity of data formats, I see this as a modest accomplishment. However, we're not quite done yet.\n",
    "\n",
    "\n",
    "### STORING THE DATA\n",
    "\n",
    "Thusfar, we have neglected to group the data by categories and have instead opted for using pdfs as keys. However, for practical purposes, this will not suffice. We must now design a cursory script to extract the name of the country and year from each report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b31408990.pdf': ('SWAZILAND', '1930'),\n",
       " 'b31409052.pdf': ('SWAZILAND', '1938'),\n",
       " 'b31409003.pdf': ('SWAZILAND', '1933'),\n",
       " 'b31409015.pdf': ('SWAZILAND', '1934'),\n",
       " 'b31408989.pdf': ('SWAZILAND', '1931'),\n",
       " 'b31409027.pdf': ('SWAZILAND', '1935'),\n",
       " 'b31409040.pdf': ('SWAZILAND', '1937'),\n",
       " 'b31409039.pdf': ('SWAZILAND', '1936'),\n",
       " 'b31409350.pdf': ('NYASALAND', '1938'),\n",
       " 'b31411514.pdf': ('TOGOLAND', '1938'),\n",
       " 'b31409106.pdf': ('CAMEROON', '1937'),\n",
       " 'b31409404.pdf': ('NORTHERN RHODESIA', '1933'),\n",
       " 'b31409362.pdf': ('NORTHERN RHODESIA', '1929'),\n",
       " 'b31410327.pdf': ('KENYA', '1938'),\n",
       " 'b31411472.pdf': ('TOGOLAND', '1934'),\n",
       " 'b31409064.pdf': ('CAMEROON', '1933'),\n",
       " 'b3141283x.pdf': ('NYASALAND', '1927'),\n",
       " 'b31412865.pdf': ('NYASALAND', '1930'),\n",
       " 'b31409325.pdf': ('NYASALAND', '1935'),\n",
       " 'b31409398.pdf': ('NORTHERN RHODESIA', '1934'),\n",
       " 'b31409374.pdf': ('NORTHERN RHODESIA', '1932'),\n",
       " 'b31411113.pdf': ('TANGANYIKA', '1938'),\n",
       " 'b3140943x.pdf': ('NORTHERN RHODESIA', '1936'),\n",
       " 'b31411071.pdf': ('TANGANYIKA', '1934'),\n",
       " 'b31410315.pdf': ('KENYA', '1937'),\n",
       " 'b31411101.pdf': ('TANGANYIKA', '1937'),\n",
       " 'b31411484.pdf': ('TOGOLAND', '1935'),\n",
       " 'b31409349.pdf': ('NYASALAND', '1937'),\n",
       " 'b31409076.pdf': ('CAMEROON', '1934'),\n",
       " 'b31409416.pdf': ('NORTHERN RHODESIA', '1936'),\n",
       " 'b31410273.pdf': ('KENYA', '1933'),\n",
       " 'b31411083.pdf': ('TANGANYIKA', '1935'),\n",
       " 'b31411095.pdf': ('TANGANYIKA', '1936'),\n",
       " 'b31409337.pdf': ('NYASALAND', '1936'),\n",
       " 'b31409301.pdf': ('NYASALAND', '1933'),\n",
       " 'b31410297.pdf': ('KENYA', '1935'),\n",
       " 'b31409428.pdf': ('NORTHERN RHODESIA', '1937'),\n",
       " 'b31411058.pdf': ('TANGANYIKA', '1932'),\n",
       " 'b31409313.pdf': ('NYASALAND', '1934'),\n",
       " 'b3140909x.pdf': ('CAMEROON', '1934'),\n",
       " 'b31409088.pdf': ('CAMEROON', '1935'),\n",
       " 'b31410261.pdf': ('KENYA', '1932'),\n",
       " 'b31411502.pdf': ('TOGOLAND', '1937'),\n",
       " 'b31409118.pdf': ('CAMEROON', '1938'),\n",
       " 'b31411496.pdf': ('TOGOLAND', '1936'),\n",
       " 'b31409295.pdf': ('NYASALAND', '1931'),\n",
       " 'b3141106x.pdf': ('TANGANYIKA', '1933')}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countryRgx = '(t?anganyika|swaziland|cameroon|ny ?as ?aland|northern rhodesia|togoland|kenya).{0,200}?(19\\d\\d)'\n",
    "\n",
    "#After we search the title page for a country,\n",
    "#there are several errors we need to correct.\n",
    "def cleanCountryRes(searchRes):\n",
    "    if re.search('ny ?as ?aland',\n",
    "                 searchRes.group(0),\n",
    "                 re.IGNORECASE):\n",
    "        return 'NYASALAND'\n",
    "    elif re.search('t?anganyika',\n",
    "                   searchRes.group(0),\n",
    "                   re.IGNORECASE):\n",
    "        return 'TANGANYIKA'\n",
    "    \n",
    "#Takes pdf, returns tuple (country, year).\n",
    "def getReportData(pdf, pagesDict):\n",
    "    firstPage = pagesDict[pdf][0]\n",
    "    countryYearRaw = re.search(countryRgx, firstPage,\n",
    "                           re.IGNORECASE|re.DOTALL)\n",
    "    countryRaw = countryYearRaw.group(1)\n",
    "    country = re.sub('ny ?as ?aland|t?anganyika', \n",
    "                     cleanCountryRes, countryRaw,\n",
    "                     flags = re.IGNORECASE)\n",
    "    \n",
    "    year = countryYearRaw.group(2)\n",
    "    \n",
    "    return (country, year)\n",
    "\n",
    "pdfData = { pdf : getReportData(pdf, texts)\n",
    "             for pdf in masterExpDict.keys() }\n",
    "\n",
    "pdfData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDict = nestedDict(4, str)\n",
    "\n",
    "for pdf, data in masterExpDict.items():\n",
    "    country, year = pdfData[pdf]\n",
    "    finalDict[country][year] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One may wonder why we need to disaggregate based on report rather than country or year; if each report contains data from multiple years, there will be overlap. However, due to both inconsistencies between the reports and errors on the part of the pdf reader, this arrangement will not suffice. Instead, we will structure data by report and allow anyone interested in the dataset to choose the datapoints they believe most accurate for any given country and year.\n",
    "\n",
    "I do intend to go through our programatically generated results and manually revise them. I'll also add in data for a handful of pdfs which were, for various reasons, unreadable by the pdf reader. (These were either cases where pages were stored as images or export tables were stored sideways.) This will be uploaded to github as a separate file. Nonetheless, I'll still show what I was able to generate programatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('codeGenerated.json', 'w+') as jsonFile:\n",
    "    json.dump(finalDict, jsonFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All in all, pretty decent use of a few days."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
